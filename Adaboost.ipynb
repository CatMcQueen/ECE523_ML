{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Adaboost.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPVfWc7XZgkrwxseEtKIr1T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CatMcQueen/ECE523_ML/blob/main/Adaboost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fSMUtS3Mw-Jf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Adaboost():\n",
        "  def __init__(self):\n",
        "    #self.weights = None\n",
        "    self.alpha = []\n",
        "    #self.error  = []\n",
        "    self.model = []\n",
        "    self.rounds = 0\n",
        "\n",
        "\n",
        "  def sample(self, N, p):\n",
        "    # this is the sample weak model\n",
        "    # from homework 1\n",
        "    random_sample = np.zeros(N)\n",
        "    p_estimate = np.zeros(len(p))\n",
        "    p_cdf = np.cumsum(p)\n",
        "    counts = np.zeros(len(p))\n",
        "\n",
        "    for n in range(N):\n",
        "        # generate a random number on [0,1]\n",
        "        x = np.random.rand()\n",
        "        random_sample[n] = int(np.where(((p_cdf > x)*1.0) == 1.)[0][0])\n",
        "        counts[int(random_sample[n])] += 1\n",
        "\n",
        "    p_estimate = counts/counts.sum()\n",
        "    random_sample = [int(x) for x in random_sample]\n",
        "    return random_sample, p_estimate\n",
        "\n",
        "  def calc_error(self, weights,  y, y_pred):\n",
        "    # error = sum(weights* [[h(i) != y(i)]])\n",
        "    # cheat and use np not equal to do the [[]] part becuase otherwise it would \n",
        "    # be a super sucky for loop that would take forever\n",
        "    # also should I be normalizing the error? I think weights\n",
        "    # should always sum to 1???\n",
        "    not_equal_part  = np.not_equal(y, y_pred)\n",
        "    err             = sum(weights * not_equal_part.astype(int))/sum(weights)\n",
        "    return err\n",
        "\n",
        "  def calc_alpha(self, error):\n",
        "    # alpha = 1/2*log((1-error)/error)\n",
        "    # np.log is the ln which is what we are using in class\n",
        "    alpha = 0\n",
        "    if(error != 0):\n",
        "      alpha = .5 * np.log((1-error)/error)\n",
        "    return alpha\n",
        "\n",
        "  def calc_weight(self, prev_weight, y, alpha, y_pred, error):\n",
        "    # Di = Di/Z * exp(-alpha * y * y_pred)\n",
        "    # Z = 1 if z = true and z=0 if false\n",
        "    #z  = np.not_equal(y, y_pred)\n",
        "    #zp = np.equal(y, y_pred)\n",
        "    zt = (1-error)*np.exp(-alpha) + (error)*np.exp(alpha)\n",
        "    new_weights = prev_weight / np.sum(zt) * np.exp(-alpha * y * y_pred)\n",
        "    return new_weights\n",
        "\n",
        "\n",
        "\n",
        "  def fit(self, x, y, rounds=20):\n",
        "    weights = np.ones(len(x))/len(x)\n",
        "    #self.weights.append(weights)\n",
        "    self.rounds = rounds\n",
        "\n",
        "    for n in range(rounds):\n",
        "      # first fit the weak model with a sample of the values\n",
        "      weakmodel = DecisionTreeClassifier(max_depth=2)\n",
        "      i, p      = self.sample(len(weights), weights)\n",
        "      weakmodel = weakmodel.fit(x[i], y[i])\n",
        "\n",
        "      # then do the steps from the lecture (4)\n",
        "      y_pred    = weakmodel.predict(x)\n",
        "      error     = self.calc_error(weights, y, y_pred)\n",
        "      alpha     = self.calc_alpha(error)\n",
        "      weights   = self.calc_weight(weights, y, alpha, y_pred, error)\n",
        "      #print(weights)\n",
        "\n",
        "      # now save off relevant values\n",
        "      #self.weights.append(weights) # doesn't look like we need these\n",
        "      #self.error.append(error) # doesn't look like we need\n",
        "      self.alpha.append(alpha)\n",
        "      self.model.append(weakmodel)\n",
        "    #yhat = sign(sum(alpha* y_pred(x)))\n",
        "    # accuracy is number of that that's right\n",
        "    #return accuracy?? I dont think I need to return anything?\n",
        "\n",
        "  def predict(self, x):\n",
        "    ## predict is y_hat = sign (sum(alpha * y_pred(x) ))\n",
        "    sumval = []\n",
        "    for n in range(self.rounds):\n",
        "      # then do the weak prediction\n",
        "      y_pred    = self.model[n].predict(x) * self.alpha[n]\n",
        "      sumval.append(y_pred)\n",
        "\n",
        "    weak_pred = np.array(sumval)\n",
        "\n",
        "    ## predict is y_hat = sign (sum(alpha * y_pred(x) ))\n",
        "    vals = np.sum(weak_pred, axis=0)\n",
        "    #print(len(vals))\n",
        "    #print(np.sign(vals))\n",
        "    y_hat = np.sign(np.sum(weak_pred, axis=0)).astype(int)\n",
        "    return y_hat\n"
      ],
      "metadata": {
        "id": "CXIso9yIxCnn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_process(pd_source, pd_target):\n",
        "  # convert data and split it into x and y\n",
        "  sourcearray = np.array(pd_source)\n",
        "  targetarray = np.array(pd_target)\n",
        "  target_x = targetarray[:, :-1] # the x1 and x2 cols\n",
        "  target_y = targetarray[:, -1]  # the y column\n",
        "  source_x = sourcearray[:, :-1] # the x1 and x2 cols\n",
        "  source_y = sourcearray[:, -1]  # the y column\n",
        "\n",
        "  # now convert it to \"matrix\" form?\n",
        "  xt = np.array(target_x)\n",
        "  yt = np.array(target_y)\n",
        "  xs = np.array(source_x)\n",
        "  ys = np.array(source_y)\n",
        "\n",
        "  return xs, ys, xt, yt"
      ],
      "metadata": {
        "id": "cMCGczZR7_7A"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# first collect the source data\n",
        "pd_target = pd.read_csv('target_train.csv', header=None,  dtype=float)\n",
        "pd_source = pd.read_csv('source_train.csv', header=None,  dtype=float)\n",
        "\n",
        "# now separate it into x and y for the source and target\n",
        "xs, ys, xt, yt = data_process(pd_source, pd_target)\n"
      ],
      "metadata": {
        "id": "OMBmH4fe7Hoy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs.shape"
      ],
      "metadata": {
        "id": "pEFX91l88G_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ada = Adaboost()\n",
        "ada.fit(xs, ys)"
      ],
      "metadata": {
        "id": "ijsqGmev_iOa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = ada.predict(xt)"
      ],
      "metadata": {
        "id": "avI521Hn_nOE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions)\n",
        "print(yt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49OZ-zz2Lk9_",
        "outputId": "c0c2b941-60ea-427d-f498-0759ac76a3fe"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1 -1  1 -1 -1  1  1  1 -1 -1 -1  1  1 -1  1  1  1  1  1 -1  1  1  1 -1\n",
            " -1  1  1 -1  1 -1  1 -1  1  1  1 -1  1 -1 -1 -1  1 -1 -1 -1 -1  1 -1  1\n",
            " -1 -1]\n",
            "[ 1. -1.  1. -1. -1.  1. -1.  1. -1. -1. -1.  1.  1. -1.  1.  1.  1.  1.\n",
            "  1. -1.  1.  1.  1. -1. -1.  1.  1. -1.  1. -1.  1. -1.  1.  1.  1. -1.\n",
            "  1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.  1. -1. -1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for i, x in enumerate(predictions):\n",
        "  if (x == int(yt[i])):\n",
        "    count += 1\n",
        "\n",
        "print (count / len(predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXf3tN4fMTzP",
        "outputId": "f72fc85c-93e9-4eb9-9c65-2052c1a4b9bb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "\n",
        "clf = AdaBoostClassifier(n_estimators=30, random_state=0)\n",
        "clf.fit(xs, ys)\n",
        "sklearn_ada = clf.predict(xt)"
      ],
      "metadata": {
        "id": "wCnzg2CgNMOQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for i, x in enumerate(sklearn_ada):\n",
        "  if (x == int(yt[i])):\n",
        "    count += 1\n",
        "\n",
        "print (count / len(predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMTqGsShGPoJ",
        "outputId": "e15a7da3-e304-4bc8-c398-e80950088cb4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "x39iEx9ZGVGr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}