import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import csv

def make_random_var(mu, sigma, n, d):
    rand = np.random.multivariate_normal(mu, sigma, size=d)
    return rand


means = [[5., 6.], [0., 2.]]
# covariance matrices for the 3 classes
covs = [[[ 5.0,  1.0],
        [ 1.5,  0.]],
        [[ 5.0,  1.0],
        [ 1.5,  0.]]]

testmeans   = [2,3]
testcovs    = [[4.,3.],
            [4., 0.]]


dim      = 2
classes  = 2
nsamples = 500
dataset  = np.zeros(( nsamples*classes, dim + 1))
for idx, mean in enumerate(means):
    xy  = make_random_var(mean, covs[idx], 2, nsamples)
    z   = np.full(xy.shape[0], idx)
    dataset[nsamples*idx:nsamples*(idx+1)] = np.array([xy[:, 0], xy[:, 1], z]).T

class LogisticReg():
    def __init__(self, learningrate):
        self.lr = learningrate
        self.w  = None

    #def e(self, x, y):
    #    res = -2 * (y - self.w.T*x)*x
    #    return res

    def sumg(self,x, y, xinit):
        result = 0
        for idx, xi in enumerate(x):
            # we could add a +b but it was mentioned in office hours it wasn't necessary
            xcur     = np.append([1.], xi)
            exponent = np.exp(-(np.dot(xcur.T, self.w)))
            g        = 1/(1 + exponent)
            xinitial = np.append([1.], xinit)
            result  += np.dot((g - y[idx]), xinitial[idx])
        #print('x: {}, exp {}, g {}, xinit {}, res {}'.format(xcur.shape, exponent, g, xinit.shape, result.shape))
        return result


    def sgd(self, dataset):
        self.w  = np.random.randn(dataset.shape[1])
        init = 0
        for i in range(5000):
            # shuffle data every time
            np.random.shuffle(dataset)
            if init==0:
                temp = self.w - self.lr * self.sumg(dataset[:, :-1], dataset[:, -1], np.ones(dataset[:,:-1].shape))
                init = 1
            else:
                # do 1/m so that the size stays small enough??
                temp = self.w - self.lr * 1/len(dataset) * self.sumg(dataset[:, :-1], dataset[:, -1], dataset[:,:-1])
            
            if np.linalg.norm(self.w-temp)**2 < 1*10^(-3):
                print('finished')
                self.w = temp
                return
            if (i % 500 == 0):
                print('norm at {}: {}'.format(i, np.linalg.norm(self.w - temp)**2))
            self.w = temp

    def predict(self,x):
        # do the whole dataset at once?
        #1000x3 * 3x1 = 1000x1
        ones        = np.ones(len(x))
        #print(x.shape)
        newx        = np.insert(x, 1, ones, axis=1)
        exponent    = np.exp(-(np.dot(newx, self.w)))
        ans         = 1/(1+exponent)
        # predict 1 if it's greater than 1/2 and 0 if it's less than half
        ypred       = np.where(ans > .5, 1, 0)
        return ypred

if __name__ == '__main__':
    filename    = '/Users/catmcqueen/Documents/SPR22/ML/data/UA-ECE-523-Sp2018/data/blood.csv'
    with open(filename,'r') as file:
        datard = csv.reader(file, delimiter=',')
        data   = [dat for dat in datard]
        
    dataarr     = np.asarray(data)
    #print(dataset.shape)
    logre = LogisticReg(learningrate = .01)
    logre.sgd(dataset)
    
    newdata = make_random_var(testmeans, testcovs, 2, 40)
    predictions = logre.predict(newdata)
    print(predictions)

    fig = plt.figure()
    ax = fig.add_subplot(111)
    colormap = np.array(['r', 'g'])
    for x,y,lab in zip(dataset[:,0],dataset[:,1],dataset[:,2]):
            ax.scatter(x,y, c =colormap[int(lab)])
    newcolormap = np.array(['y', 'b'])
    for x,y,lab in zip(newdata[:,0], newdata[:,1], predictions):
            ax.scatter(x,y, c=newcolormap[int(lab)])
    plt.show()

    
