
from ast import Num
from termios import NL1
import numpy as np
import matplotlib.pyplot as plt

def gen_cb(N, a, alpha): 
    """
    N: number of points on the checkerboard
    a: width of the checker board (0<a<1)
    alpha: rotation of the checkerboard in radians 
    """
    d = np.random.rand(N, 2).T
    d_transformed = np.array([d[0]*np.cos(alpha)-d[1]*np.sin(alpha), 
                              d[0]*np.sin(alpha)+d[1]*np.cos(alpha)]).T
    s = np.ceil(d_transformed[:,0]/a)+np.floor(d_transformed[:,1]/a)
    lab = 2 - (s%2)
    data = d.T
    return data, lab 
'''
X, y = gen_cb(250, .5, 0)
plt.plot(X[np.where(y==1)[0], 0], X[np.where(y==1)[0], 1], 'o')
plt.plot(X[np.where(y==2)[0], 0], X[np.where(y==2)[0], 1], 's', c = 'r')

X, y = gen_cb(5000, .25, 3.14159/4)
plt.figure()
plt.plot(X[np.where(y==1)[0], 0], X[np.where(y==1)[0], 1], 'o')
plt.plot(X[np.where(y==2)[0], 0], X[np.where(y==2)[0], 1], 's', c = 'r')
plt.show()
'''
def knn(datax, datay, x):
    # get euclidian distance from all points to this one
    diff = datax - x
    # the closest one will be the one that has the smallest sqrt(x1^2 + x2^2)
    values  = np.array([np.sqrt((r[0]**2 + r[1]**2)) for r in diff])
    idx     = np.argsort(values)
    nn      = values[idx][0:10]
    lab     = datay[idx][0:10]
    # p(x) = (k/n)/V
    vol     = 3.14159 * nn[-1]**2 # volume = pi*r**2
    n1      = np.where(lab==1)[0]#find the labels 1 in the region
    n2      = np.where(lab==2)[0]# find the labels 2 in the region
    p1      = float(len(n1))/len(lab)/vol
    p2      = float(len(n2))/len(lab)/vol
    return p1, p2



def calculate_posterior(datax, datay, x, dist=1):
    #maximum likelihood = # instances in class / # instances in dataset
    y1 = np.where(datay==1)
    y2 = np.where(datay==2)
    py1 = float(len(y1)) / len(datay) # # of y==1 / # of total samples
    py2 = float(len(y2)) / len(datay) # # of y==2 / # of total samples
    post = np.zeros((len(x),2))
    probx_giveny = np.zeros((len(x),len(x[0])))
    for i, xi in enumerate(x):
        probx_given1, probx_given2 = knn(datax, datay, xi)
        probx_giveny[i, 0] = probx_given1 # p(x|y==1)
        probx_giveny[i, 1] = probx_given2 # p(x|y==2)
        probx = py1*probx_given1 + py2*probx_given2 # total probability theorem
        # do the posterior that it's part of the given distribution
        post[i,0] = probx_given1 * py1 / (probx)
        post[i,1] = probx_given2 * py2 / (probx)
    posteriorpred = np.argmax(np.array(post), axis=1)
    return posteriorpred, probx_giveny

# I have no idea how this is supposed to work but let's do matplotlib
# scatter with c-coor instead?
'''
def plotColorProb(x, pxgy):
    print(x.shape, pxgy.shape)
    d   = 1./len(x)
    # slice = (start, stop step)
    # use mgrid across both (0-x)
    # stepping by 1/x every time
    y,x = np.mgrid[slice(0, len(x), d), slice(0,len(x),d)]
    plt.pcolor(x, x, pxgy)
    plt.show()
'''

def plotColorProb(x, pxgy):
    plt.scatter(x[0], x[1], c=pxgy)


if __name__ == "__main__":
    X, y = gen_cb(10000, .25, 3.14159/4)
    trainx, trainy  = X[:6500], y[:6500]
    testx, testy    = X[6500:], y[6500:]
    post, pxgy = calculate_posterior(trainx, trainy, testx)
            
    error = np.mean((post - testy)**2)
    print(error)

    # now plot probability of x given y
    plt.scatter(testx[:,0], testx[:,1], c=pxgy[:,1])
    plt.title('P(y=2|x)')
    plt.show()
    #plotColorProb(testx, pxgy)
    



    #plt.figure()
    #plt.plot(trainx[np.where(trainy==1)[0], 0], trainx[np.where(trainy==1)[0], 1], 'o')
    #plt.plot(trainx[np.where(trainy==2)[0], 0], trainx[np.where(trainy==2)[0], 1], 's', c = 'r')

    #plt.show()
    


